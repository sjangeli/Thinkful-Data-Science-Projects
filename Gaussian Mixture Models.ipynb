{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets, metrics\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "postgres_user = 'dsbc_student'\n",
    "postgres_pw = '7*.8G9QH21'\n",
    "postgres_host = '142.93.121.174'\n",
    "postgres_port = '5432'\n",
    "postgres_db = 'heartdisease'\n",
    "\n",
    "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
    "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
    "\n",
    "heartdisease_df = pd.read_sql_query('select * from heartdisease',con=engine)\n",
    "\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and the outcome\n",
    "X = heartdisease_df.iloc[:, :13]\n",
    "y = heartdisease_df.iloc[:, 13]\n",
    "\n",
    "# Replace missing values (marked by ?) with a 0\n",
    "X = X.replace(to_replace='?', value=0)\n",
    "\n",
    "# Binarize y so that 1 means heart disease diagnosis and 0 means no diagnosis\n",
    "y = np.where(y > 0, 0, 1)\n",
    "\n",
    "# Standarizing the features\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GMM to the heart disease data by setting n_components=2. Get ARI and silhoutte scores for your solution and compare it with those of the k-means and hierarchical clustering solutions that you implemented in the assignments of the previous checkpoints. Which algorithm does perform better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index of the GMM solution: 0.4207322145049338\n",
      "The silhoutte score of the GMM solution: 0.16118591340148433\n"
     ]
    }
   ],
   "source": [
    "# Defining the agglomerative clustering\n",
    "gmm_cluster = GaussianMixture(n_components=2, random_state=13)\n",
    "\n",
    "# Fit model\n",
    "clusters = gmm_cluster.fit_predict(X_std)\n",
    "\n",
    "print(\"Adjusted Rand Index of the GMM solution: {}\"\n",
    "      .format(metrics.adjusted_rand_score(y, clusters)))\n",
    "print(\"The silhoutte score of the GMM solution: {}\"\n",
    "      .format(metrics.silhouette_score(X_std, clusters, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means: ARI .43 and Silhouette .17\n",
    "Hierarchical: ARI .14 and Silhouette .14\n",
    "GMM: ARI .42 and Silhouette .16\n",
    "\n",
    "K means slightly outperforms GMM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMM implementation of scikit-learn has a parameter called covariance_type. This parameter determines the type of covariance parameters to use. Specifically, there are four types you can specify:\n",
    "\n",
    "#### full: This is the default. Each component has its own general covariance matrix.\n",
    "#### tied: All components share the same general covariance matrix.\n",
    "#### diag: Each component has its own diagonal covariance matrix.\n",
    "#### spherical: Each component has its own single variance.\n",
    "#### Try all of these. Which one does perform better in terms of ARI and silhouette scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index of the GMM solution: 0.4207322145049338\n",
      "The silhoutte score of the GMM solution: 0.16118591340148433\n"
     ]
    }
   ],
   "source": [
    "# Defining the agglomerative clustering\n",
    "gmm_cluster = GaussianMixture(n_components=2, random_state=13, covariance_type='full')\n",
    "\n",
    "# Fit model\n",
    "clusters = gmm_cluster.fit_predict(X_std)\n",
    "\n",
    "print(\"Adjusted Rand Index of the GMM solution: {}\"\n",
    "      .format(metrics.adjusted_rand_score(y, clusters)))\n",
    "print(\"The silhoutte score of the GMM solution: {}\"\n",
    "      .format(metrics.silhouette_score(X_std, clusters, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index of the GMM solution: 0.46482432589803474\n",
      "The silhoutte score of the GMM solution: 0.1660701212463109\n"
     ]
    }
   ],
   "source": [
    "# Defining the agglomerative clustering\n",
    "gmm_cluster = GaussianMixture(n_components=2, random_state=13, covariance_type='tied')\n",
    "\n",
    "# Fit model\n",
    "clusters = gmm_cluster.fit_predict(X_std)\n",
    "\n",
    "print(\"Adjusted Rand Index of the GMM solution: {}\"\n",
    "      .format(metrics.adjusted_rand_score(y, clusters)))\n",
    "print(\"The silhoutte score of the GMM solution: {}\"\n",
    "      .format(metrics.silhouette_score(X_std, clusters, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index of the GMM solution: 0.3870024156200561\n",
      "The silhoutte score of the GMM solution: 0.1604139815113049\n"
     ]
    }
   ],
   "source": [
    "# Defining the agglomerative clustering\n",
    "gmm_cluster = GaussianMixture(n_components=2, random_state=13, covariance_type='diag')\n",
    "\n",
    "# Fit model\n",
    "clusters = gmm_cluster.fit_predict(X_std)\n",
    "\n",
    "print(\"Adjusted Rand Index of the GMM solution: {}\"\n",
    "      .format(metrics.adjusted_rand_score(y, clusters)))\n",
    "print(\"The silhoutte score of the GMM solution: {}\"\n",
    "      .format(metrics.silhouette_score(X_std, clusters, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Rand Index of the GMM solution: 0.20765243525722465\n",
      "The silhoutte score of the GMM solution: 0.12468753110276873\n"
     ]
    }
   ],
   "source": [
    "# Defining the agglomerative clustering\n",
    "gmm_cluster = GaussianMixture(n_components=2, random_state=13, covariance_type='spherical')\n",
    "\n",
    "# Fit model\n",
    "clusters = gmm_cluster.fit_predict(X_std)\n",
    "\n",
    "print(\"Adjusted Rand Index of the GMM solution: {}\"\n",
    "      .format(metrics.adjusted_rand_score(y, clusters)))\n",
    "print(\"The silhoutte score of the GMM solution: {}\"\n",
    "      .format(metrics.silhouette_score(X_std, clusters, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance = tied performs the best on both ARI and Silhouette."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
